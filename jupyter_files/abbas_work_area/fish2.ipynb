{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../../dataset/fish.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns='Length2')\n",
    "df_test = df_test.drop(columns='Length2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasist.structdata import detect_outliers\n",
    "\n",
    "idx = detect_outliers(\n",
    "    data=df,\n",
    "    n=0,  \n",
    "    features=['Weight', 'Length1', 'Length3']\n",
    ")\n",
    "\n",
    "# Remove the outliers\n",
    "df_clean = df.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>51.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>4.5924</td>\n",
       "      <td>2.6316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3</td>\n",
       "      <td>567.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>48.7</td>\n",
       "      <td>7.7920</td>\n",
       "      <td>4.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>6.1100</td>\n",
       "      <td>3.4075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>25.3</td>\n",
       "      <td>7.0334</td>\n",
       "      <td>3.8203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.3680</td>\n",
       "      <td>4.2340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>250.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.4</td>\n",
       "      <td>7.8204</td>\n",
       "      <td>4.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>37.2</td>\n",
       "      <td>14.9544</td>\n",
       "      <td>5.1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.7920</td>\n",
       "      <td>3.6240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>300.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>28.7</td>\n",
       "      <td>8.3230</td>\n",
       "      <td>5.1373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species  Weight  Length1  Length3   Height   Width\n",
       "75         2    51.5     15.0     17.2   4.5924  2.6316\n",
       "138        3   567.0     43.2     48.7   7.7920  4.8700\n",
       "2          0   340.0     23.9     31.1  12.3778  4.6961\n",
       "86         2   120.0     20.0     23.5   6.1100  3.4075\n",
       "45         4   160.0     20.5     25.3   7.0334  3.8203\n",
       "..       ...     ...      ...      ...      ...     ...\n",
       "71         1   300.0     24.0     29.0  11.3680  4.2340\n",
       "106        2   250.0     25.9     29.4   7.8204  4.2042\n",
       "14         0   600.0     29.4     37.2  14.9544  5.1708\n",
       "92         2   150.0     20.5     24.0   6.7920  3.6240\n",
       "102        2   300.0     25.2     28.7   8.3230  5.1373\n",
       "\n",
       "[127 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = df_train.select_dtypes(exclude = np.number).columns\n",
    "le = LabelEncoder()\n",
    "classes = dict()\n",
    "for i in category:\n",
    "    df_train[i] = le.fit_transform(df_train[i])\n",
    "    classes[i] = le.classes_\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>19.4</td>\n",
       "      <td>5.1992</td>\n",
       "      <td>3.1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>1.2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>200.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>5.5680</td>\n",
       "      <td>3.3756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6</td>\n",
       "      <td>270.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>28.7</td>\n",
       "      <td>8.3804</td>\n",
       "      <td>4.2476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>5.2185</td>\n",
       "      <td>3.6260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>18.9570</td>\n",
       "      <td>6.6030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1.7284</td>\n",
       "      <td>1.1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>180.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.0866</td>\n",
       "      <td>3.9060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>188.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>26.2</td>\n",
       "      <td>6.7334</td>\n",
       "      <td>4.1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>59.7</td>\n",
       "      <td>10.6863</td>\n",
       "      <td>6.9849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.7</td>\n",
       "      <td>14.4738</td>\n",
       "      <td>5.7276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>43.5</td>\n",
       "      <td>12.3540</td>\n",
       "      <td>6.5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>37.2</td>\n",
       "      <td>15.4380</td>\n",
       "      <td>5.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>22.4</td>\n",
       "      <td>8.8928</td>\n",
       "      <td>3.2928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>31.9</td>\n",
       "      <td>40.5</td>\n",
       "      <td>16.2405</td>\n",
       "      <td>5.5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.1</td>\n",
       "      <td>18.0369</td>\n",
       "      <td>6.3063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>40.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>12.6040</td>\n",
       "      <td>8.1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>218.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.1680</td>\n",
       "      <td>4.1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>225.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>7.2930</td>\n",
       "      <td>3.7230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>14.8604</td>\n",
       "      <td>5.2854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2.2139</td>\n",
       "      <td>1.2838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>38.6</td>\n",
       "      <td>15.6330</td>\n",
       "      <td>5.1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>13.7592</td>\n",
       "      <td>4.3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>36.2</td>\n",
       "      <td>14.2266</td>\n",
       "      <td>4.9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.0840</td>\n",
       "      <td>6.2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>40.1</td>\n",
       "      <td>45.5</td>\n",
       "      <td>12.5125</td>\n",
       "      <td>7.4165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.2750</td>\n",
       "      <td>3.7250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>270.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>29.3</td>\n",
       "      <td>8.1454</td>\n",
       "      <td>4.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.7388</td>\n",
       "      <td>1.0476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2.2139</td>\n",
       "      <td>1.1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>510.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>6.8250</td>\n",
       "      <td>4.4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>18.5</td>\n",
       "      <td>4.5880</td>\n",
       "      <td>2.9415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species  Weight  Length1  Length3   Height   Width\n",
       "78         2    78.0     16.8     19.4   5.1992  3.1234\n",
       "155        5    13.4     11.7     13.5   2.4300  1.2690\n",
       "128        3   200.0     30.0     34.8   5.5680  3.3756\n",
       "55         6   270.0     23.6     28.7   8.3804  4.2476\n",
       "94         2   150.0     21.0     24.5   5.2185  3.6260\n",
       "29         0  1000.0     33.5     42.6  18.9570  6.6030\n",
       "147        5     7.0     10.1     11.6   1.7284  1.1484\n",
       "51         4   180.0     23.6     27.9   7.0866  3.9060\n",
       "98         2   188.0     22.6     26.2   6.7334  4.1658\n",
       "141        3  1250.0     52.0     59.7  10.6863  6.9849\n",
       "19         0   650.0     31.0     38.7  14.4738  5.7276\n",
       "60         6  1000.0     37.3     43.5  12.3540  6.5250\n",
       "15         0   600.0     29.4     37.2  15.4380  5.5800\n",
       "65         1   150.0     18.4     22.4   8.8928  3.2928\n",
       "24         0   700.0     31.9     40.5  16.2405  5.5890\n",
       "30         0   920.0     35.0     44.1  18.0369  6.3063\n",
       "126        2  1000.0     40.2     46.0  12.6040  8.1420\n",
       "101        2   218.0     25.0     28.0   7.1680  4.1440\n",
       "96         2   225.0     22.0     25.5   7.2930  3.7230\n",
       "16         0   700.0     30.4     38.3  14.8604  5.2854\n",
       "151        5    10.0     11.3     13.1   2.2139  1.2838\n",
       "18         0   610.0     30.9     38.6  15.6330  5.1338\n",
       "12         0   500.0     29.1     36.4  13.7592  4.3680\n",
       "9          0   500.0     28.5     36.2  14.2266  4.9594\n",
       "31         0   955.0     35.0     44.0  18.0840  6.2920\n",
       "125        2  1100.0     40.1     45.5  12.5125  7.4165\n",
       "95         2   170.0     21.5     25.0   6.2750  3.7250\n",
       "56         6   270.0     24.1     29.3   8.1454  4.2485\n",
       "145        5     6.7      9.3     10.8   1.7388  1.0476\n",
       "152        5     9.9     11.3     13.1   2.2139  1.1659\n",
       "135        3   510.0     40.0     45.5   6.8250  4.4590\n",
       "76         2    70.0     15.7     18.5   4.5880  2.9415"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "classes = dict()\n",
    "cat = df_test.select_dtypes(exclude = np.number).columns\n",
    "for i in cat:\n",
    "    df_test[i] = le.fit_transform(df_test[i])\n",
    "    classes[i] = le.classes_\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.    , 15.    , 17.2   ,  4.5924,  2.6316],\n",
       "       [ 3.    , 43.2   , 48.7   ,  7.792 ,  4.87  ],\n",
       "       [ 0.    , 23.9   , 31.1   , 12.3778,  4.6961],\n",
       "       [ 2.    , 20.    , 23.5   ,  6.11  ,  3.4075],\n",
       "       [ 4.    , 20.5   , 25.3   ,  7.0334,  3.8203],\n",
       "       [ 4.    , 19.4   , 23.7   ,  6.1146,  3.2943],\n",
       "       [ 1.    , 19.8   , 24.1   ,  9.7364,  3.1571],\n",
       "       [ 2.    , 36.6   , 41.3   , 12.4313,  7.3514],\n",
       "       [ 0.    , 32.    , 40.6   , 16.3618,  6.09  ],\n",
       "       [ 3.    , 42.    , 48.    ,  6.96  ,  4.896 ],\n",
       "       [ 5.    , 10.    , 11.6   ,  1.972 ,  1.16  ],\n",
       "       [ 2.    , 20.    , 23.5   ,  5.5225,  3.995 ],\n",
       "       [ 1.    , 19.    , 23.2   ,  8.5376,  3.2944],\n",
       "       [ 4.    , 16.5   , 20.3   ,  5.2983,  2.8217],\n",
       "       [ 2.    , 19.    , 22.5   ,  5.6925,  3.555 ],\n",
       "       [ 0.    , 31.5   , 39.7   , 15.5227,  5.2801],\n",
       "       [ 2.    , 19.3   , 22.8   ,  6.384 ,  3.534 ],\n",
       "       [ 2.    , 18.2   , 21.    ,  5.082 ,  2.772 ],\n",
       "       [ 2.    , 34.    , 39.    , 10.881 ,  6.864 ],\n",
       "       [ 0.    , 28.7   , 36.2   , 14.3714,  4.8146],\n",
       "       [ 2.    , 30.5   , 34.    , 10.03  ,  6.018 ],\n",
       "       [ 1.    , 21.2   , 25.8   , 10.3458,  3.6636],\n",
       "       [ 2.    , 41.1   , 46.6   , 12.4888,  7.5958],\n",
       "       [ 0.    , 32.7   , 41.5   , 16.517 ,  5.8515],\n",
       "       [ 5.    , 10.8   , 12.6   ,  1.9782,  1.2852],\n",
       "       [ 2.    , 39.8   , 45.2   , 11.9328,  7.2772],\n",
       "       [ 4.    , 19.1   , 23.1   ,  6.1677,  3.3957],\n",
       "       [ 0.    , 26.5   , 34.    , 12.444 ,  5.134 ],\n",
       "       [ 3.    , 40.    , 45.5   ,  7.28  ,  4.3225],\n",
       "       [ 0.    , 36.2   , 45.3   , 18.7542,  6.7497],\n",
       "       [ 3.    , 48.3   , 55.1   ,  8.9262,  6.1712],\n",
       "       [ 2.    , 25.4   , 28.9   ,  7.2828,  4.5662],\n",
       "       [ 1.    , 19.    , 23.2   ,  9.396 ,  3.4104],\n",
       "       [ 0.    , 28.4   , 36.2   , 14.2628,  5.1042],\n",
       "       [ 2.    , 20.7   , 24.2   ,  5.9532,  3.63  ],\n",
       "       [ 3.    , 34.8   , 39.8   ,  6.2884,  4.0198],\n",
       "       [ 0.    , 23.2   , 30.    , 11.52  ,  4.02  ],\n",
       "       [ 2.    , 36.5   , 41.4   , 11.1366,  6.003 ],\n",
       "       [ 1.    , 17.5   , 21.3   ,  8.3922,  2.9181],\n",
       "       [ 4.    , 20.5   , 24.3   ,  6.6339,  3.5478],\n",
       "       [ 2.    , 19.    , 22.5   ,  5.6925,  3.6675],\n",
       "       [ 0.    , 32.8   , 41.6   , 16.8896,  6.1984],\n",
       "       [ 4.    , 19.    , 22.8   ,  6.4752,  3.3516],\n",
       "       [ 2.    , 32.5   , 37.3   , 11.4884,  7.7957],\n",
       "       [ 0.    , 31.8   , 40.9   , 16.36  ,  6.0532],\n",
       "       [ 0.    , 31.8   , 40.6   , 15.4686,  6.1306],\n",
       "       [ 2.    , 34.6   , 39.3   , 10.5717,  6.3666],\n",
       "       [ 2.    , 17.2   , 20.2   ,  5.6358,  3.0502],\n",
       "       [ 4.    , 18.6   , 22.2   ,  6.216 ,  3.5742],\n",
       "       [ 3.    , 56.    , 64.    ,  9.6   ,  6.144 ],\n",
       "       [ 2.    , 25.4   , 28.9   ,  7.0516,  4.335 ],\n",
       "       [ 5.    , 11.5   , 13.4   ,  2.0904,  1.3936],\n",
       "       [ 3.    , 36.    , 41.    ,  6.396 ,  3.977 ],\n",
       "       [ 4.    , 21.1   , 25.    ,  6.4   ,  3.8   ],\n",
       "       [ 2.    , 36.9   , 42.3   , 11.9286,  7.1064],\n",
       "       [ 1.    , 13.5   , 16.5   ,  6.8475,  2.3265],\n",
       "       [ 2.    , 12.5   , 14.7   ,  3.528 ,  1.9992],\n",
       "       [ 0.    , 37.4   , 45.9   , 18.6354,  6.7473],\n",
       "       [ 2.    , 27.8   , 31.6   ,  7.6156,  4.7716],\n",
       "       [ 5.    , 10.4   , 12.    ,  2.196 ,  1.38  ],\n",
       "       [ 2.    , 39.    , 44.6   , 12.8002,  6.8684],\n",
       "       [ 1.    , 14.3   , 17.4   ,  6.5772,  2.3142],\n",
       "       [ 5.    , 13.2   , 15.2   ,  2.8728,  2.0672],\n",
       "       [ 2.    , 22.    , 25.5   ,  6.375 ,  3.825 ],\n",
       "       [ 2.    , 23.5   , 27.    ,  6.561 ,  4.239 ],\n",
       "       [ 4.    , 25.    , 30.6   ,  8.568 ,  4.7736],\n",
       "       [ 0.    , 26.8   , 34.7   , 13.6024,  4.9274],\n",
       "       [ 2.    , 34.5   , 39.4   , 10.835 ,  6.2646],\n",
       "       [ 2.    , 37.1   , 42.5   , 11.135 ,  6.63  ],\n",
       "       [ 4.    , 22.    , 26.7   ,  6.9153,  3.6312],\n",
       "       [ 4.    , 12.9   , 16.2   ,  4.1472,  2.268 ],\n",
       "       [ 2.    , 17.8   , 20.8   ,  5.1376,  3.0368],\n",
       "       [ 2.    , 16.2   , 19.2   ,  5.2224,  3.3216],\n",
       "       [ 0.    , 38.    , 46.5   , 17.6235,  6.3705],\n",
       "       [ 4.    , 21.    , 25.    ,  6.55  ,  3.325 ],\n",
       "       [ 0.    , 27.6   , 35.    , 12.67  ,  4.69  ],\n",
       "       [ 4.    , 20.4   , 24.7   ,  5.8045,  3.7544],\n",
       "       [ 1.    , 23.    , 28.    , 11.088 ,  4.144 ],\n",
       "       [ 2.    , 37.    , 42.5   , 11.73  ,  7.225 ],\n",
       "       [ 2.    , 32.    , 36.5   , 10.2565,  6.3875],\n",
       "       [ 2.    , 20.5   , 24.    ,  5.856 ,  3.624 ],\n",
       "       [ 2.    , 19.    , 22.5   ,  5.9175,  3.3075],\n",
       "       [ 3.    , 56.    , 64.    ,  9.6   ,  6.144 ],\n",
       "       [ 3.    , 59.    , 68.    , 10.812 ,  7.48  ],\n",
       "       [ 2.    , 20.    , 23.5   ,  5.875 ,  3.525 ],\n",
       "       [ 0.    , 27.6   , 35.1   , 14.0049,  4.8438],\n",
       "       [ 2.    , 34.    , 38.3   , 10.6091,  6.7408],\n",
       "       [ 0.    , 29.5   , 37.3   , 13.9129,  5.0728],\n",
       "       [ 6.    , 33.7   , 39.6   , 11.7612,  6.5736],\n",
       "       [ 3.    , 40.1   , 45.8   ,  7.786 ,  5.1296],\n",
       "       [ 0.    , 26.3   , 33.5   , 12.73  ,  4.4555],\n",
       "       [ 0.    , 30.4   , 38.5   , 14.938 ,  5.1975],\n",
       "       [ 4.    , 18.2   , 22.2   ,  5.6166,  3.1746],\n",
       "       [ 2.    ,  7.5   ,  8.8   ,  2.112 ,  1.408 ],\n",
       "       [ 3.    , 44.8   , 51.2   ,  7.68  ,  5.376 ],\n",
       "       [ 0.    , 26.8   , 34.5   , 14.1795,  5.2785],\n",
       "       [ 3.    , 35.5   , 40.5   ,  7.29  ,  4.5765],\n",
       "       [ 1.    , 16.3   , 19.8   ,  7.4052,  2.673 ],\n",
       "       [ 4.    , 29.5   , 35.    ,  9.485 ,  5.355 ],\n",
       "       [ 2.    , 26.9   , 30.1   ,  7.5852,  4.6354],\n",
       "       [ 4.    , 22.1   , 26.8   ,  7.3968,  4.1272],\n",
       "       [ 5.    , 12.1   , 13.8   ,  2.277 ,  1.2558],\n",
       "       [ 6.    , 28.5   , 34.    , 10.744 ,  6.562 ],\n",
       "       [ 4.    , 22.    , 27.2   ,  7.5344,  3.8352],\n",
       "       [ 2.    , 20.    , 23.5   ,  6.11  ,  3.525 ],\n",
       "       [ 0.    , 31.4   , 39.2   , 15.9936,  5.3704],\n",
       "       [ 6.    , 25.6   , 30.8   ,  8.778 ,  4.6816],\n",
       "       [ 5.    , 11.4   , 13.2   ,  2.2044,  1.1484],\n",
       "       [ 3.    , 31.7   , 37.8   ,  5.7078,  4.158 ],\n",
       "       [ 4.    , 17.5   , 21.2   ,  5.5756,  2.9044],\n",
       "       [ 5.    , 10.7   , 12.4   ,  2.0832,  1.2772],\n",
       "       [ 0.    , 24.    , 31.2   , 12.48  ,  4.3056],\n",
       "       [ 4.    , 24.    , 29.2   ,  8.8768,  4.4968],\n",
       "       [ 3.    , 32.7   , 38.8   ,  5.9364,  4.3844],\n",
       "       [ 2.    , 25.4   , 28.9   ,  7.1672,  4.335 ],\n",
       "       [ 2.    , 23.    , 26.5   ,  6.4395,  3.6835],\n",
       "       [ 2.    , 36.5   , 41.4   , 11.1366,  7.4934],\n",
       "       [ 2.    , 20.    , 23.5   ,  5.64  ,  3.525 ],\n",
       "       [ 2.    , 13.8   , 16.    ,  3.824 ,  2.432 ],\n",
       "       [ 2.    , 37.    , 42.4   , 12.3808,  7.4624],\n",
       "       [ 5.    , 13.8   , 16.2   ,  2.9322,  1.8792],\n",
       "       [ 0.    , 31.3   , 39.5   , 15.1285,  5.5695],\n",
       "       [ 1.    , 24.    , 29.    , 11.368 ,  4.234 ],\n",
       "       [ 2.    , 25.9   , 29.4   ,  7.8204,  4.2042],\n",
       "       [ 0.    , 29.4   , 37.2   , 14.9544,  5.1708],\n",
       "       [ 2.    , 20.5   , 24.    ,  6.792 ,  3.624 ],\n",
       "       [ 2.    , 25.2   , 28.7   ,  8.323 ,  5.1373]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train.drop(columns = 'Weight').values\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  51.5,  567. ,  340. ,  120. ,  160. ,  120. ,  145. ,  820. ,\n",
       "        720. ,  500. ,    7.5,  110. ,  140. ,   69. ,  110. ,  620. ,\n",
       "        130. ,   85. ,  685. ,  500. ,  514. ,  200. , 1000. ,  714. ,\n",
       "          8.7, 1000. ,  110. ,  430. ,  456. ,  925. ,  950. ,  250. ,\n",
       "        170. ,  475. ,  145. ,  300. ,  242. ,  650. ,  120. ,  145. ,\n",
       "        125. ,  850. ,    0. ,  840. ,  725. ,  680. ,  690. ,   80. ,\n",
       "        120. , 1600. ,  265. ,   12.2,  345. ,  160. ,  850. ,   55. ,\n",
       "         32. ,  975. ,  320. ,    9.7, 1100. ,   60. ,   19.7,  145. ,\n",
       "        197. ,  272. ,  450. ,  700. ,  820. ,  161. ,   40. ,   85. ,\n",
       "        100. ,  950. ,  140. ,  390. ,  150. ,  273. ,  900. ,  556. ,\n",
       "        130. ,  115. , 1550. , 1650. ,  135. ,  450. ,  700. ,  340. ,\n",
       "        800. ,  540. ,  363. ,  700. ,   87. ,    5.9,  770. ,  500. ,\n",
       "        430. ,   90. ,  390. ,  300. ,  200. ,   12.2,  540. ,  169. ,\n",
       "        130. ,  685. ,  306. ,    9.8,  300. ,   78. ,    9.8,  290. ,\n",
       "        290. ,  300. ,  260. ,  180. ,  900. ,  120. ,   40. , 1015. ,\n",
       "         19.9,  575. ,  300. ,  250. ,  600. ,  150. ,  300. ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train['Weight'].values\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.drop(columns = 'Weight').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test['Weight'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - R2Score: -1.3112 - loss: 223699.6406   \n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - R2Score: -1.0544 - loss: 231761.9844\n",
      "Epoch 3/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8082 - loss: 226118.4062 \n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.6618 - loss: 215980.3906 \n",
      "Epoch 5/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - R2Score: -0.6828 - loss: 223895.6719  \n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.4691 - loss: 171842.8281 \n",
      "Epoch 7/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.4837 - loss: 184347.3438 \n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.3808 - loss: 190353.7969 \n",
      "Epoch 9/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - R2Score: -0.3436 - loss: 157862.4062 \n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - R2Score: -0.3178 - loss: 140165.0625\n",
      "Epoch 11/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - R2Score: -0.2774 - loss: 175149.2656 \n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - R2Score: -0.2640 - loss: 148096.5312  \n",
      "Epoch 13/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - R2Score: -0.1491 - loss: 138108.7812  \n",
      "Epoch 14/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - R2Score: -0.1320 - loss: 136774.3750  \n",
      "Epoch 15/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - R2Score: -0.1043 - loss: 121756.2656\n",
      "Epoch 16/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.1588 - loss: 130990.0156 \n",
      "Epoch 17/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - R2Score: -0.1114 - loss: 146679.9688 \n",
      "Epoch 18/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.0762 - loss: 136440.9375 \n",
      "Epoch 19/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.0583 - loss: 125317.7188\n",
      "Epoch 20/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - R2Score: -0.0620 - loss: 130714.9766 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - R2Score: -0.1269 - loss: 160291.6875\n",
      "Test accuracy: -0.12691569328308105\n",
      "Test loss: 160291.6875\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define the neural network model\n",
    "model = models.Sequential([\n",
    "    # Input layer (flattened images)\n",
    "    layers.InputLayer(input_shape=(5,)),\n",
    "    \n",
    "    # First hidden layer with 16 neurons and ReLU activation\n",
    "    layers.Dense(5, activation='relu'),\n",
    "    \n",
    "    # Second hidden layer with 16 neurons and ReLU activation\n",
    "    layers.Dense(5, activation='relu'),\n",
    "\n",
    "    # Output layer with 10 neurons and softmax activation for classification\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer=optimizers.SGD(learning_rate=0.01),\n",
    "              loss='mse', \n",
    "              metrics=['R2Score'])\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Step 6: Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
