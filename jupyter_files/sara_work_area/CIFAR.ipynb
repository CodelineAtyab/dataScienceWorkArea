{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_dir = r'C:\\Users\\71524\\Downloads\\train\\train'\n",
    "labels_file  = r'C:\\Users\\71524\\OneDrive - omantel.om\\Documents\\Pandas\\dataScienceWorkArea\\jupyter_files\\sara_work_area\\trainLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_dir = #path_to_dataset\n",
    "labels_file  = r'C:\\Users\\71524\\OneDrive - omantel.om\\Documents\\Pandas\\dataScienceWorkArea\\jupyter_files\\sara_work_area\\trainLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_file)\n",
    "image_size = 32  # CIFAR-10 images are 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and preprocess images\n",
    "def load_images(image_ids, train_dir):\n",
    "    images = []\n",
    "    for img_id in image_ids:\n",
    "        img_path = os.path.join(train_dir, f\"{img_id}.png\")\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# List of image IDs from the labels dataframe\n",
    "image_ids = labels_df['id'].values  # Assuming 'id' column has image IDs\n",
    "\n",
    "# Load images\n",
    "X = load_images(image_ids, train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Normalize the image data\n",
    "X = X / 255.0  # Normalize pixel values to the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Flatten the images (from 32x32x3 to 3072)\n",
    "X_flat = X.reshape(X.shape[0], -1)  # Shape: (num_samples, 32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the string labels into integers\n",
    "y = label_encoder.fit_transform(labels_df['label'].values)\n",
    "\n",
    "# One-hot encode the labels for classification\n",
    "y = to_categorical(y, num_classes=10)  # CIFAR-10 has 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\71524\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.2613 - loss: 2.0349 - val_accuracy: 0.3627 - val_loss: 1.7586\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.3765 - loss: 1.7257 - val_accuracy: 0.4015 - val_loss: 1.6639\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.4054 - loss: 1.6466 - val_accuracy: 0.4274 - val_loss: 1.5876\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.4402 - loss: 1.5614 - val_accuracy: 0.4380 - val_loss: 1.5569\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.4520 - loss: 1.5254 - val_accuracy: 0.4280 - val_loss: 1.5930\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.4669 - loss: 1.4917 - val_accuracy: 0.4396 - val_loss: 1.5638\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.4773 - loss: 1.4570 - val_accuracy: 0.4596 - val_loss: 1.5138\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.4907 - loss: 1.4253 - val_accuracy: 0.4341 - val_loss: 1.6069\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.4962 - loss: 1.3998 - val_accuracy: 0.4608 - val_loss: 1.5251\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.5025 - loss: 1.3818 - val_accuracy: 0.4571 - val_loss: 1.5309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eb7bb151c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Define the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(512, input_dim=3072, activation='relu'))  # 3072 input features (32*32*3)\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))  # 10 output classes for CIFAR-10\n",
    "\n",
    "# Step 8: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 9: Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4604 - loss: 1.5266\n",
      "Test accuracy: 0.4571000039577484\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.2791 - loss: 2.0170 - val_accuracy: 0.3710 - val_loss: 1.7256\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.3881 - loss: 1.7080 - val_accuracy: 0.4055 - val_loss: 1.6718\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.4218 - loss: 1.6189 - val_accuracy: 0.4120 - val_loss: 1.6242\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.4463 - loss: 1.5564 - val_accuracy: 0.4368 - val_loss: 1.5587\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.4549 - loss: 1.5204 - val_accuracy: 0.4340 - val_loss: 1.5683\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.4728 - loss: 1.4835 - val_accuracy: 0.4583 - val_loss: 1.5142\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.4781 - loss: 1.4645 - val_accuracy: 0.4422 - val_loss: 1.5357\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.4850 - loss: 1.4359 - val_accuracy: 0.4582 - val_loss: 1.5082\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.4965 - loss: 1.4147 - val_accuracy: 0.4397 - val_loss: 1.5999\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.4959 - loss: 1.3997 - val_accuracy: 0.4719 - val_loss: 1.4913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eb7bb2ad50>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Define the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(512, input_dim=3072, activation='relu'))  # 3072 input features (32*32*3)\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))  # 10 output classes for CIFAR-10\n",
    "\n",
    "# Step 8: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 9: Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4681 - loss: 1.4944\n",
      "Test accuracy: 0.47189998626708984\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.2294 - loss: 2.0742 - val_accuracy: 0.3588 - val_loss: 1.7704\n",
      "Epoch 2/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.3604 - loss: 1.7629 - val_accuracy: 0.3704 - val_loss: 1.7360\n",
      "Epoch 3/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.3996 - loss: 1.6650 - val_accuracy: 0.4235 - val_loss: 1.6219\n",
      "Epoch 4/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.4246 - loss: 1.6021 - val_accuracy: 0.4198 - val_loss: 1.5982\n",
      "Epoch 5/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.4454 - loss: 1.5398 - val_accuracy: 0.4119 - val_loss: 1.6498\n",
      "Epoch 6/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.4614 - loss: 1.5102 - val_accuracy: 0.4402 - val_loss: 1.5528\n",
      "Epoch 7/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.4792 - loss: 1.4595 - val_accuracy: 0.4562 - val_loss: 1.5263\n",
      "Epoch 8/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.4949 - loss: 1.4176 - val_accuracy: 0.4711 - val_loss: 1.4818\n",
      "Epoch 9/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.4921 - loss: 1.4119 - val_accuracy: 0.4715 - val_loss: 1.4908\n",
      "Epoch 10/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.5049 - loss: 1.3818 - val_accuracy: 0.4760 - val_loss: 1.4910\n",
      "Epoch 11/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.5153 - loss: 1.3478 - val_accuracy: 0.4785 - val_loss: 1.4681\n",
      "Epoch 12/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.5249 - loss: 1.3290 - val_accuracy: 0.4801 - val_loss: 1.4635\n",
      "Epoch 13/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.5365 - loss: 1.3004 - val_accuracy: 0.4857 - val_loss: 1.4626\n",
      "Epoch 14/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.5421 - loss: 1.2670 - val_accuracy: 0.4715 - val_loss: 1.5082\n",
      "Epoch 15/15\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.5456 - loss: 1.2652 - val_accuracy: 0.4919 - val_loss: 1.4605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eb2e6f58b0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Define the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(512, input_dim=3072, activation='relu'))  # 3072 input features (32*32*3)\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))  # 10 output classes for CIFAR-10\n",
    "\n",
    "# Step 8: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 9: Train the model\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4927 - loss: 1.4534\n",
      "Test accuracy: 0.4918999969959259\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the CNN model\n",
    "cnn_model = Sequential([\n",
    "    # Convolutional layer with 32 filters, 3x3 kernel, ReLU activation\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Max pooling layer to reduce spatial size\n",
    "\n",
    "    # Convolutional layer with 64 filters, 3x3 kernel, ReLU activation\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Convolutional layer with 128 filters, 3x3 kernel, ReLU activation\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Flatten layer to convert the 3D feature maps to 1D\n",
    "    Flatten(),\n",
    "\n",
    "    # Fully connected layer\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    # Output layer with 10 neurons for 10 classes (CIFAR-10)\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.3186 - loss: 1.8389 - val_accuracy: 0.5034 - val_loss: 1.3874\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.5431 - loss: 1.2803 - val_accuracy: 0.5754 - val_loss: 1.2326\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.6082 - loss: 1.1120 - val_accuracy: 0.6310 - val_loss: 1.0490\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.6625 - loss: 0.9700 - val_accuracy: 0.6663 - val_loss: 0.9794\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.6915 - loss: 0.8833 - val_accuracy: 0.6767 - val_loss: 0.9383\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7202 - loss: 0.8029 - val_accuracy: 0.6836 - val_loss: 0.9337\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7435 - loss: 0.7378 - val_accuracy: 0.6875 - val_loss: 0.9116\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7648 - loss: 0.6693 - val_accuracy: 0.7038 - val_loss: 0.8800\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7852 - loss: 0.6223 - val_accuracy: 0.7037 - val_loss: 0.9011\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8000 - loss: 0.5784 - val_accuracy: 0.7008 - val_loss: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eb373cc920>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Compile the model\n",
    "cnn_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 3: Train the model\n",
    "cnn_model.fit(X, y, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 - 5s - 3ms/step - accuracy: 0.7872 - loss: 0.6329\n",
      "Test accuracy: 0.7871999740600586\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Evaluate the model\n",
    "test_loss, test_acc = cnn_model.evaluate(X, y, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
