{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08d1b9e",
   "metadata": {},
   "source": [
    "\n",
    "# Classification in Machine Learning\n",
    "\n",
    "## Introduction to Classification\n",
    "\n",
    "Classification is a supervised learning technique that predicts the category or class label of new observations based on past observations. Classification problems can be categorized as:\n",
    "\n",
    "- **Binary Classification**: The output variable has two possible classes (e.g., spam/not spam).\n",
    "- **Multi-Class Classification**: The output variable has more than two classes (e.g., classifying types of flowers).\n",
    "- **Multi-Label Classification**: Each observation can be assigned multiple labels (e.g., tagging images with multiple objects).\n",
    "\n",
    "### Popular Classification Algorithms\n",
    "\n",
    "- **Logistic Regression**: A linear model that estimates the probability of a binary outcome.\n",
    "- **k-Nearest Neighbors (k-NN)**: Classifies new data points based on the majority class of its k nearest neighbors.\n",
    "- **Support Vector Machine (SVM)**: Finds the optimal hyperplane that separates classes in the feature space.\n",
    "- **Decision Trees**: Classifies data by learning decision rules inferred from features.\n",
    "- **Random Forest**: An ensemble method that builds multiple decision trees and merges them to improve accuracy.\n",
    "\n",
    "## Data Preparation for Classification\n",
    "\n",
    "### Data Preprocessing Steps\n",
    "\n",
    "1. **Handling Missing Data**: Handle missing data by imputation or removing rows/columns.\n",
    "2. **Encoding Categorical Variables**: Convert categorical variables into numerical format using techniques like one-hot encoding or label encoding.\n",
    "3. **Feature Scaling**: Standardize or normalize features to ensure that they are on the same scale.\n",
    "\n",
    "### Splitting Data into Training and Testing Sets\n",
    "\n",
    "To evaluate the performance of a model, data is split into training and testing sets. The training set is used to train the model, while the testing set is used to evaluate its performance.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "## Model Training and Evaluation\n",
    "\n",
    "### Logistic Regression Example\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model training\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "```\n",
    "\n",
    "### Random Forest Example\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model training\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "```\n",
    "\n",
    "### Support Vector Machine (SVM) Example\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Model training\n",
    "svm_clf = SVC(probability=True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "```\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "Common metrics for evaluating classification models include:\n",
    "\n",
    "- **Accuracy**: The proportion of correctly classified instances.\n",
    "- **Precision**: The proportion of true positive instances among the instances classified as positive.\n",
    "- **Recall**: The proportion of true positive instances among the instances that should have been classified as positive.\n",
    "- **F1 Score**: The harmonic mean of precision and recall.\n",
    "- **ROC-AUC**: Area Under the Receiver Operating Characteristic Curve, which measures the model's ability to distinguish between classes.\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table used to describe the performance of a classification model. It compares the actual target values with those predicted by the model.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_log_reg)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### ROC Curve for SVM\n",
    "\n",
    "The ROC curve is a graphical representation of the true positive rate (TPR) versus the false positive rate (FPR) at various threshold settings. The area under the curve (AUC) provides an aggregate measure of performance.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score_svm[:, 1], pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - SVM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we've covered the basics of classification in machine learning, explored different classification algorithms, and demonstrated how to implement and evaluate them using Python and scikit-learn.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
